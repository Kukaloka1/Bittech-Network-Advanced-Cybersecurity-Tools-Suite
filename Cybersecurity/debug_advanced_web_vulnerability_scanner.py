import requests
from bs4 import BeautifulSoup
import dns.resolver
import socket
import ssl
from urllib.parse import urlparse, parse_qs, urljoin
from concurrent.futures import ThreadPoolExecutor, as_completed
import re
import json
import warnings
import nmap
import whois
import subprocess
import time
from packaging import version

warnings.filterwarnings("ignore", category=requests.packages.urllib3.exceptions.InsecureRequestWarning)

class AdvancedProfessionalWebVulnerabilityScanner:
    def __init__(self, target_url):
        self.target_url = target_url
        self.domain = urlparse(target_url).netloc
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        })
        self.results = {
            "domain_info": {},
            "dns_info": {},
            "whois_info": {},
            "ssl_info": {},
            "headers": {},
            "technologies": [],
            "open_ports": [],
            "vulnerabilities": [],
            "sensitive_files": [],
            "subdomains": []
        }

    def run_scan(self):
        print(f"Starting advanced scan of {self.target_url}")
        
        functions = [
            self.get_domain_info,
            self.check_dns,
            self.get_whois_info,
            self.check_ssl,
            self.check_headers,
            self.detect_technologies,
            self.scan_ports,
            self.check_common_vulnerabilities,
            self.find_sensitive_files,
            self.discover_subdomains
        ]
        
        for func in functions:
            try:
                print(f"Running {func.__name__}...")
                func()
                print(f"{func.__name__} completed.")
            except Exception as e:
                print(f"Error in {func.__name__}: {str(e)}")
        
        self.print_results()

    def get_domain_info(self):
        try:
            ip = socket.gethostbyname(self.domain)
            self.results["domain_info"]["ip"] = ip
            try:
                hostname, _, _ = socket.gethostbyaddr(ip)
                self.results["domain_info"]["hostname"] = hostname
            except socket.herror:
                self.results["domain_info"]["hostname"] = "Hostname could not be resolved"
        except socket.gaierror:
            self.results["domain_info"]["error"] = "Could not resolve the domain"

    def check_dns(self):
        for qtype in ['A', 'AAAA', 'MX', 'NS', 'TXT', 'SOA']:
            try:
                answers = dns.resolver.resolve(self.domain, qtype)
                self.results["dns_info"][qtype] = [str(rdata) for rdata in answers]
            except dns.resolver.NoAnswer:
                self.results["dns_info"][qtype] = "No records found"
            except Exception as e:
                self.results["dns_info"][qtype] = f"Error: {str(e)}"

    def get_whois_info(self):
        try:
            w = whois.whois(self.domain)
            self.results["whois_info"] = {
                "registrar": w.registrar,
                "creation_date": str(w.creation_date),
                "expiration_date": str(w.expiration_date),
                "name_servers": w.name_servers
            }
        except Exception as e:
            self.results["whois_info"]["error"] = str(e)

    def check_ssl(self):
        try:
            context = ssl.create_default_context()
            with socket.create_connection((self.domain, 443)) as sock:
                with context.wrap_socket(sock, server_hostname=self.domain) as secure_sock:
                    cert = secure_sock.getpeercert()
                    self.results["ssl_info"] = {
                        "version": secure_sock.version(),
                        "cipher": secure_sock.cipher(),
                        "expiration": cert['notAfter'],
                        "subject": dict(x[0] for x in cert['subject']),
                        "issuer": dict(x[0] for x in cert['issuer'])
                    }
        except Exception as e:
            self.results["ssl_info"]["error"] = str(e)

    def check_headers(self):
        try:
            response = self.session.get(self.target_url, verify=False, timeout=10)
            self.results["headers"] = dict(response.headers)
        except requests.exceptions.RequestException as e:
            self.results["headers"]["error"] = str(e)

    def detect_technologies(self):
        try:
            response = self.session.get(self.target_url, verify=False, timeout=10)
            soup = BeautifulSoup(response.text, 'html.parser')
            
            tech_patterns = {
                'jQuery': {'pattern': r'jquery.*\.js', 'type': 'script'},
                'React': {'pattern': r'react.*\.js', 'type': 'script'},
                'Vue.js': {'pattern': r'vue.*\.js', 'type': 'script'},
                'Angular': {'pattern': r'angular.*\.js', 'type': 'script'},
                'Bootstrap': {'pattern': r'bootstrap.*\.css', 'type': 'link'},
                'WordPress': {'pattern': r'wp-content', 'type': 'content'},
            }
            
            for tech, data in tech_patterns.items():
                if data['type'] == 'script' and soup.find('script', src=re.compile(data['pattern'], re.I)):
                    self.results["technologies"].append(tech)
                elif data['type'] == 'link' and soup.find('link', href=re.compile(data['pattern'], re.I)):
                    self.results["technologies"].append(tech)
                elif data['type'] == 'content' and re.search(data['pattern'], response.text, re.I):
                    self.results["technologies"].append(tech)
        except requests.exceptions.RequestException as e:
            self.results["technologies"].append(f"Error: {str(e)}")

    def scan_ports(self):
        try:
            nm = nmap.PortScanner()
            nm.scan(self.domain, arguments='-p 80,443,8080,8443 -sV')
            for host in nm.all_hosts():
                for proto in nm[host].all_protocols():
                    lport = nm[host][proto].keys()
                    for port in lport:
                        self.results["open_ports"].append({
                            "port": port,
                            "state": nm[host][proto][port]['state'],
                            "service": nm[host][proto][port]['name'],
                            "version": nm[host][proto][port]['version']
                        })
        except Exception as e:
            self.results["open_ports"].append(f"Error: {str(e)}")

    def check_common_vulnerabilities(self):
        self.check_xss()

    def check_xss(self):
        payloads = ["<script>alert('XSS')</script>", "<img src=x onerror=alert('XSS')>"]
        vulnerable_params = []
        
        try:
            response = self.session.get(self.target_url, verify=False, timeout=10)
            parsed = urlparse(response.url)
            params = parse_qs(parsed.query)
            
            for param in params:
                for payload in payloads:
                    test_url = self.target_url.replace(f"{param}={params[param][0]}", f"{param}={payload}")
                    try:
                        r = self.session.get(test_url, verify=False, timeout=5)
                        if payload in r.text:
                            vulnerable_params.append(param)
                            break
                    except:
                        pass
            
            if vulnerable_params:
                self.results["vulnerabilities"].append({
                    "type": "xss",
                    "details": f"Possible XSS in parameters: {', '.join(vulnerable_params)}"
                })
        except Exception as e:
            self.results["vulnerabilities"].append({"type": "error", "details": f"Error checking XSS: {str(e)}"})

    def find_sensitive_files(self):
        sensitive_files = ['/robots.txt', '/sitemap.xml', '/.env', '/.git/config']
        for file in sensitive_files:
            try:
                url = urljoin(self.target_url, file)
                response = self.session.get(url, verify=False, timeout=5)
                if response.status_code == 200:
                    self.results["sensitive_files"].append(url)
            except:
                pass

    def discover_subdomains(self):
        subdomains = [f"www.{self.domain}", f"mail.{self.domain}", f"ftp.{self.domain}"]
        for subdomain in subdomains:
            try:
                ip = socket.gethostbyname(subdomain)
                self.results["subdomains"].append(subdomain)
            except:
                pass

    def print_results(self):
        print("\n--- Scan Results ---\n")
        print(json.dumps(self.results, indent=4))

if __name__ == "__main__":
    target = input("Enter the target URL (including http:// or https://): ")
    scanner = AdvancedProfessionalWebVulnerabilityScanner(target)
    scanner.run_scan()
